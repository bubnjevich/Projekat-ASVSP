services:
  spark-master:
    image: spark-custom:3.0.1-hadoop3.2.1
    container_name: spark-master
    environment:
      - SPARK_NO_DAEMONIZE=1
    command: ["/opt/spark/sbin/start-master.sh"]
    ports:
      - "8000:8080"
      - "7077:7077"
    networks: [asvsp]
    restart: unless-stopped

  spark-worker-1:
    image: spark-custom:3.0.1-hadoop3.2.1
    container_name: spark-worker-1
    depends_on: [spark-master]
    environment:
      - SPARK_NO_DAEMONIZE=1
    command: ["/opt/spark/sbin/start-slave.sh", "spark://spark-master:7077"]
    ports:
      - "8001:8081"
    networks: [asvsp]
    restart: unless-stopped

  spark-worker-2:
    image: spark-custom:3.0.1-hadoop3.2.1
    container_name: spark-worker-2
    depends_on: [spark-master]
    environment:
      - SPARK_NO_DAEMONIZE=1
    command: ["/opt/spark/sbin/start-slave.sh", "spark://spark-master:7077"]
    ports:
      - "8002:8081"
    networks: [asvsp]
    restart: unless-stopped

networks:
  asvsp:
    name: asvsp
    external: true
